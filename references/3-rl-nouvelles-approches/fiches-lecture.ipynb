{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "807dbb1d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÑ Article 1 : Nazari et al. (2018) ‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "**R√©f√©rence compl√®te** :\n",
    "- Auteurs : Nazari, M., Oroojlooy, A., Snyder, L., Tak√°c, M.\n",
    "- Ann√©e : 2018\n",
    "- Titre : *Reinforcement Learning for Solving the Vehicle Routing Problem*\n",
    "- Source : NeurIPS\n",
    "- Fichier PDF : `Reinforcement Learning for Solving the Vehicle Routing Problem.pdf`\n",
    "\n",
    "**üî• ARTICLE CL√â** : C'est LE papier qui va inspirer ta m√©thodologie. √Ä lire EN PROFONDEUR.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Question 1 : Quel est le probl√®me principal ?\n",
    "\n",
    "**R√©ponse** :\n",
    "\n",
    "*[√Ä compl√©ter ‚Äî Ex : R√©soudre le VRP avec RL au lieu d'heuristiques classiques]*\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Question 2 : Comment les auteurs s'y prennent-ils ?\n",
    "\n",
    "**R√©ponse** :\n",
    "\n",
    "*[√Ä compl√©ter ‚Äî Ex : Ils mod√©lisent le VRP comme un MDP, utilisent un r√©seau attention-based...]*\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Question 3 : Quelle est la conclusion principale ?\n",
    "\n",
    "**R√©ponse** :\n",
    "\n",
    "*[√Ä compl√©ter ‚Äî Ex : Le RL surpasse les heuristiques classiques sur des instances de taille moyenne...]*\n",
    "\n",
    "---\n",
    "\n",
    "### üß† D√©tails Techniques pour Impl√©mentation RL\n",
    "\n",
    "#### 1Ô∏è‚É£ D√©finition du MDP\n",
    "\n",
    "**√âtat (State)** :\n",
    "- Repr√©sentation : *[√Ä compl√©ter ‚Äî Ex : Coordonn√©es des clients, capacit√© restante...]*\n",
    "- Dimension : *[√Ä compl√©ter]*\n",
    "- Type : Continu / Discret / Hybride\n",
    "\n",
    "**Action (Action)** :\n",
    "- Espace d'action : *[√Ä compl√©ter ‚Äî Ex : S√©lectionner le prochain client √† visiter]*\n",
    "- Dimension : *[√Ä compl√©ter]*\n",
    "- Type : Discret / Continu\n",
    "\n",
    "**R√©compense (Reward)** :\n",
    "- Formule : *[√Ä compl√©ter ‚Äî Ex : R = -distance_totale ou -co√ªt_total]*\n",
    "- P√©nalit√©s : *[Violations de contraintes, etc.]*\n",
    "\n",
    "**Transition** :\n",
    "- D√©terministe / Stochastique ?\n",
    "\n",
    "---\n",
    "\n",
    "#### 2Ô∏è‚É£ Architecture du R√©seau de Neurones\n",
    "\n",
    "- **Type de r√©seau** : *[MLP / CNN / RNN / Attention / GNN]*\n",
    "- **Nombre de couches** : *[√Ä compl√©ter]*\n",
    "- **Fonction d'activation** : *[ReLU / Tanh / ...]*\n",
    "- **M√©canisme attention** : Oui / Non ‚Äî *[D√©tails si oui]*\n",
    "\n",
    "---\n",
    "\n",
    "#### 3Ô∏è‚É£ Algorithme RL Utilis√©\n",
    "\n",
    "- **Nom** : *[PPO / DQN / A2C / SAC / Policy Gradient / ...]*\n",
    "- **On-policy / Off-policy** :\n",
    "- **Hyperparam√®tres cl√©s** : *[Learning rate, discount factor Œ≥, ...]*\n",
    "\n",
    "---\n",
    "\n",
    "#### 4Ô∏è‚É£ Entra√Ænement\n",
    "\n",
    "- **Nombre d'√©pisodes** : *[√Ä compl√©ter]*\n",
    "- **Dur√©e d'entra√Ænement** : *[Heures / Jours]*\n",
    "- **Hardware utilis√©** : *[GPU / CPU]*\n",
    "- **Curriculum learning** : Oui / Non\n",
    "\n",
    "---\n",
    "\n",
    "#### 5Ô∏è‚É£ R√©sultats et M√©triques\n",
    "\n",
    "- **M√©triques utilis√©es** : *[Ex : Distance totale, temps de calcul, gap avec optimal...]*\n",
    "- **Baselines compar√©es** : *[Ex : Dijkstra, OR-Tools, heuristiques...]*\n",
    "- **Performance** : *[Am√©lioration de X% par rapport √†...]*\n",
    "\n",
    "---\n",
    "\n",
    "### üîó Transf√©rabilit√© √† Mon Projet\n",
    "\n",
    "**Ce que je peux directement r√©utiliser** :\n",
    "1. *[Ex : La structure MDP ‚Äî adapter l'√©tat pour inclure position camion, √©tat routes...]*\n",
    "2. *[Ex : Le m√©canisme attention pour g√©rer la flotte dynamiquement]*\n",
    "3. *[√Ä compl√©ter]*\n",
    "\n",
    "**Ce que je dois adapter** :\n",
    "1. *[Ex : La fonction de r√©compense ‚Äî ajouter consommation carburant, usure...]*\n",
    "2. *[Ex : L'espace d'action ‚Äî inclure vitesse cible en plus de l'itin√©raire]*\n",
    "3. *[√Ä compl√©ter]*\n",
    "\n",
    "**Questions ouvertes / Points √† clarifier** :\n",
    "- *[Ex : Comment g√©rer la stochasticit√© (d√©gradation routes) ?]*\n",
    "- *[√Ä compl√©ter]*\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Figures/Tableaux Cl√©s\n",
    "\n",
    "- **Figure X** : Architecture du r√©seau attention\n",
    "- **Tableau Y** : Comparaison performances\n",
    "- *[√Ä compl√©ter]*\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Statut\n",
    "\n",
    "- [ ] Premi√®re lecture (Titre+Abstract+Conclusion) ‚Äî 30 min\n",
    "- [ ] Lecture approfondie (MDP, Architecture, R√©sultats) ‚Äî 2h\n",
    "- [ ] MDP adapt√© √† mon probl√®me minier ‚Äî Not√©\n",
    "- [ ] Impl√©mentation commenc√©e\n",
    "\n",
    "**Date** : | **Temps total** :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b6d191",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÑ Article 2 : Liu & Chai (2019)\n",
    "\n",
    "**R√©f√©rence compl√®te** :\n",
    "- Auteurs : Liu, X. & Chai, X.\n",
    "- Ann√©e : 2019\n",
    "- Titre : *Optimizing Open-Pit Truck Route Based on Minimization of Time-Varying Transport Energy Consumption*\n",
    "- Source : Mathematical Problems in Engineering\n",
    "- Fichier PDF : `Optimizing Open-Pit Truck Route Based on Minimization of Time-Varying Transport Energy Consumption.pdf`\n",
    "\n",
    "**üéØ FOCUS** : Fonction de r√©compense bas√©e sur la consommation d'√©nergie/carburant.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Question 1 : Quel est le probl√®me principal ?\n",
    "\n",
    "*[√Ä compl√©ter]*\n",
    "\n",
    "### ‚ùì Question 2 : M√©thodologie ?\n",
    "\n",
    "*[√Ä compl√©ter]*\n",
    "\n",
    "### ‚ùì Question 3 : Conclusion ?\n",
    "\n",
    "*[√Ä compl√©ter]*\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ Mod√®le de Consommation d'√ânergie\n",
    "\n",
    "**Formule principale** :\n",
    "\n",
    "```\n",
    "[√Ä extraire de l'article ‚Äî Ex : E = f(vitesse, charge, pente, √©tat_route)]\n",
    "```\n",
    "\n",
    "**Variables prises en compte** :\n",
    "- Vitesse : *[Oui/Non ‚Äî Comment ?]*\n",
    "- Charge du camion : *[Oui/Non]*\n",
    "- Pente de la route : *[Oui/Non]*\n",
    "- √âtat de la route : *[Oui/Non]*\n",
    "- Conditions m√©t√©o : *[Oui/Non]*\n",
    "\n",
    "**Param√®tres du mod√®le** :\n",
    "- *[Coefficients, constantes √† noter]*\n",
    "\n",
    "---\n",
    "\n",
    "### üîó Int√©gration dans ma Fonction de R√©compense\n",
    "\n",
    "**R√©compense propos√©e** :\n",
    "\n",
    "```\n",
    "R = -Œ±¬∑E(fuel) - Œ≤¬∑Time - Œ≥¬∑WaitTime - Œ¥¬∑Wear\n",
    "```\n",
    "\n",
    "O√π `E(fuel)` sera calcul√© selon la formule de Liu & Chai (2019).\n",
    "\n",
    "**Poids √† ajuster** : Œ±, Œ≤, Œ≥, Œ¥\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Statut\n",
    "\n",
    "- [ ] Premi√®re lecture\n",
    "- [ ] Formule de consommation extraite\n",
    "- [ ] Impl√©ment√©e dans le simulateur\n",
    "\n",
    "**Date** : | **Temps** :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10de720",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÑ Article 3 : Zhang et al. (2020)\n",
    "\n",
    "**R√©f√©rence compl√®te** :\n",
    "- Auteurs : Zhang, C. et al.\n",
    "- Ann√©e : 2020\n",
    "- Titre : *Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning*\n",
    "- Source : NeurIPS\n",
    "- Fichier PDF : `Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning.pdf`\n",
    "\n",
    "**üöÄ AVANC√â** : Utilisation de Graph Neural Networks (GNN) ‚Äî √Ä lire si temps disponible.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Questions Standard\n",
    "\n",
    "*[√Ä compl√©ter ‚Äî structure identique]*\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Architecture GNN\n",
    "\n",
    "**Pourquoi un graphe ?**\n",
    "- *[√Ä compl√©ter ‚Äî Ex : Le r√©seau routier minier est naturellement un graphe...]*\n",
    "\n",
    "**Type de GNN utilis√©** :\n",
    "- GCN / GAT / GraphSAGE / Autre : *[√Ä identifier]*\n",
    "\n",
    "**Repr√©sentation des n≈ìuds** :\n",
    "- *[Features associ√©s aux n≈ìuds du graphe]*\n",
    "\n",
    "**Repr√©sentation des ar√™tes** :\n",
    "- *[Poids, attributs]*\n",
    "\n",
    "---\n",
    "\n",
    "### üîó Transf√©rabilit√©\n",
    "\n",
    "**Mon graphe minier pourrait avoir** :\n",
    "- **N≈ìuds** : Points de chargement, d√©chargement, intersections, zones tampons\n",
    "- **Ar√™tes** : Routes avec attributs (distance, √©tat, pente, trafic)\n",
    "- **Features n≈ìuds** : Occupation, temps d'attente, priorit√©\n",
    "- **Features ar√™tes** : √âtat route, consommation estim√©e\n",
    "\n",
    "**Complexit√© d'impl√©mentation** : √âlev√©e (biblioth√®ques : PyTorch Geometric, DGL)\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Statut\n",
    "\n",
    "- [ ] Premi√®re lecture\n",
    "- [ ] Approche GNN comprise\n",
    "- [ ] D√©cision : Impl√©menter GNN ou rester MLP ?\n",
    "\n",
    "**Date** : | **Temps** :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bbd9c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÑ Article 4 : Optimization-Based Dispatching Policies\n",
    "\n",
    "**R√©f√©rence** :\n",
    "- Titre : *Optimization-Based Dispatching Policies for Open-Pit Mining*\n",
    "- Fichier : `Optimization-Based Dispatching Policies for Open-Pit Mining.pdf`\n",
    "\n",
    "### ‚ùì Questions + üß† D√©tails Techniques\n",
    "\n",
    "*[√Ä compl√©ter ‚Äî structure identique]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6695889",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Tableau Comparatif des Approches RL\n",
    "\n",
    "| Article | Probl√®me | Algorithme RL | Architecture R√©seau | √âtat | Action | R√©compense |\n",
    "|---------|----------|---------------|---------------------|------|--------|------------|\n",
    "| Nazari (2018) | VRP | [√Ä remplir] | Attention | [√Ä remplir] | [√Ä remplir] | -distance |\n",
    "| Liu (2019) | Route camion | [√Ä remplir] | [√Ä remplir] | [√Ä remplir] | [√Ä remplir] | -√©nergie |\n",
    "| Zhang (2020) | Job Shop | [√Ä remplir] | GNN | [√Ä remplir] | [√Ä remplir] | [√Ä remplir] |\n",
    "| Optim-Based | Dispatching | [√Ä remplir] | [√Ä remplir] | [√Ä remplir] | [√Ä remplir] | [√Ä remplir] |\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Synth√®se pour Mon Agent RL\n",
    "\n",
    "Apr√®s lecture de ces articles, d√©finir la conception de mon agent :\n",
    "\n",
    "### Mon MDP (Draft Initial)\n",
    "\n",
    "**√âtat** :\n",
    "```python\n",
    "state = {\n",
    "    'position_camion': (x, y),\n",
    "    'destination': (x_dest, y_dest),\n",
    "    'charge_actuelle': float,  # tonnes\n",
    "    'etat_route_local': array,  # d√©gradation routes voisines\n",
    "    'trafic_local': array,      # occupation routes voisines\n",
    "    'occupation_destinations': dict,  # pelles/concasseurs libres ?\n",
    "    # ... √† affiner\n",
    "}\n",
    "```\n",
    "\n",
    "**Action** :\n",
    "```python\n",
    "action = {\n",
    "    'prochain_noeud': int,      # N≈ìud suivant dans le graphe\n",
    "    'vitesse_cible': float,     # km/h (optionnel ‚Äî peut √™tre continu)\n",
    "}\n",
    "```\n",
    "\n",
    "**R√©compense** :\n",
    "```python\n",
    "R = -Œ±¬∑fuel_consumed - Œ≤¬∑time_elapsed - Œ≥¬∑wait_time - Œ¥¬∑wear_cost\n",
    "```\n",
    "\n",
    "O√π `fuel_consumed` utilise le mod√®le de Liu & Chai (2019).\n",
    "\n",
    "---\n",
    "\n",
    "### Algorithme RL Choisi\n",
    "\n",
    "**Candidats** :\n",
    "- PPO (Proximal Policy Optimization) ‚Äî Stable, on-policy\n",
    "- SAC (Soft Actor-Critic) ‚Äî Off-policy, actions continues\n",
    "- DQN ‚Äî Si action discr√®te uniquement\n",
    "\n",
    "**D√©cision finale** : *[√Ä d√©cider apr√®s lectures]*\n",
    "\n",
    "---\n",
    "\n",
    "### Architecture R√©seau\n",
    "\n",
    "**Option 1 ‚Äî MLP Simple** :\n",
    "- Input : Vecteur √©tat aplati\n",
    "- Hidden layers : 2-3 couches (128-256 neurons)\n",
    "- Output : Distribution d'actions (Policy) + Value\n",
    "\n",
    "**Option 2 ‚Äî GNN (avanc√©)** :\n",
    "- Input : Graphe du r√©seau routier\n",
    "- GNN layers : 2-3 couches\n",
    "- Output : Policy sur les n≈ìuds\n",
    "\n",
    "**D√©cision** : Commencer MLP, tester GNN si r√©sultats insuffisants.\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Plan d'Impl√©mentation RL\n",
    "\n",
    "1. ‚úÖ D√©finir MDP complet (√âtat, Action, R√©compense)\n",
    "2. ‚úÖ Impl√©menter environnement Gymnasium\n",
    "3. ‚úÖ Tester avec agent al√©atoire (sanity check)\n",
    "4. ‚úÖ Impl√©menter baseline simple (Dijkstra)\n",
    "5. ‚úÖ Entra√Æner agent RL (PPO/SAC) avec Stable-Baselines3\n",
    "6. ‚úÖ √âvaluer et comparer baselines vs RL\n",
    "7. ‚úÖ Tuning hyperparam√®tres (Optuna)\n",
    "8. ‚úÖ (Optionnel) Tester architecture GNN"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
